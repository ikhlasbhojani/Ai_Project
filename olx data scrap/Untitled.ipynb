{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48cee3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "for i in range(2):\n",
    "    URL = f\"https://www.olx.com.pk/motorcycles_c81?page={i}\"\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US, en;q=0.5\"\n",
    "    }\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    html = webpage.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all('div', class_='_9bea76df')\n",
    "    links = []\n",
    "    for result in results:\n",
    "        links.extend(result.find_all('a'))\n",
    "    href_links = []\n",
    "    for i in range(len(links)):\n",
    "        href_links.append(links[i].get(\"href\"))\n",
    "    unique_list = []\n",
    "    for item in href_links:\n",
    "        if item not in unique_list:\n",
    "            unique_list.append(item)\n",
    "    href_links = unique_list\n",
    "    with open('outputs.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for i in range(len(href_links)):\n",
    "            product_list = \"https://www.olx.com.pk\" + href_links[i]\n",
    "            new_webpage = requests.get(product_list, headers=HEADERS)\n",
    "            new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "            details = new_soup.find_all(\"div\", class_=\"b44ca0b3\")\n",
    "            detail = []\n",
    "            for i in range(min(4, len(details))):\n",
    "                detail += details[i]\n",
    "            even_details = []\n",
    "            if detail[0].text == \"Make\":\n",
    "                even_details.append(detail[1])\n",
    "            else:\n",
    "                even_details.append(None)\n",
    "            if detail[2].text == \"Model\":\n",
    "                even_details.append(detail[3])\n",
    "            else:\n",
    "                even_details.append(None)\n",
    "            if detail[4].text == \"Year\":\n",
    "                even_details.append(detail[5])\n",
    "            else:\n",
    "                even_details.append(None)\n",
    "            if detail[6].text == \"Price\":\n",
    "                even_details.append(detail[7])\n",
    "            else:\n",
    "                even_details.append(None)\n",
    "\n",
    "            row = []\n",
    "            for item in even_details:\n",
    "                if item is not None:\n",
    "                    row.append(item.text)\n",
    "                else:\n",
    "                    row.append(None)\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20a113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
